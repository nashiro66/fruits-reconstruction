{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "def set_root_path():\n",
    "    if os.getcwd().endswith('figures'):\n",
    "        os.chdir('../')\n",
    "set_root_path()\n",
    "sys.path.append('python/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import mitsuba as mi\n",
    "\n",
    "mi.set_variant('cuda_ad_rgb')\n",
    "\n",
    "from practical_reconstruction import optimization_cli\n",
    "from core import integrators\n",
    "from core import bsdfs\n",
    "from core import textures\n",
    "from core import emitters\n",
    "\n",
    "integrators.register()\n",
    "bsdfs.register()\n",
    "textures.register()\n",
    "emitters.register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_float(f):\n",
    "  \"\"\"Formats a float such that 0.1 becomes \"0_1\", 10.0 becomes \"10_0\", etc.\"\"\"\n",
    "  return str(f).replace('.', '_')\n",
    "\n",
    "scene_name = 'leather_bag'\n",
    "techniques = ['naive', 'mipmap_pyramid', 'large_steps','gradient_filtering']\n",
    "\n",
    "skip_existing = True\n",
    "\n",
    "technique_configs = {\n",
    "    'naive': [{'lr': 0.1}],\n",
    "    'mipmap_pyramid': [{'lr': 0.01}],\n",
    "    'large_steps': [{'lr': 0.1,'lambda':1.0}],\n",
    "    'gradient_filtering': [{'lr': 0.1,'sigma_d':0.001}],\n",
    "}\n",
    "\n",
    "for technique in techniques:\n",
    "    technique_params = technique_configs[technique]\n",
    "    use_gradient_filtering = technique == 'gradient_filtering'\n",
    "    use_conjugate_gradient_large_steps = technique == 'large_steps'\n",
    "\n",
    "    for technique_param in technique_params:\n",
    "        base_learning_rate = technique_param['lr']\n",
    "        if use_gradient_filtering:\n",
    "            sigma_d = technique_param['sigma_d']\n",
    "            # For gradient filtering, recomended by authors\n",
    "            filtering_steps = 4\n",
    "        else:\n",
    "            # unused\n",
    "            sigma_d = 0.0\n",
    "            filtering_steps = 0\n",
    " \n",
    "\n",
    "        print(\n",
    "            f'******** Running {technique} with base learning rate'\n",
    "            f' {base_learning_rate} ********'\n",
    "        )\n",
    "\n",
    "        override_bindings = []\n",
    "        result_folder = f'results/{scene_name}/{technique}'\n",
    "\n",
    "        result_folder += f'_lr_{format_float(base_learning_rate)}'\n",
    "        override_bindings.append(\n",
    "            f'SceneConfig.base_learning_rate={base_learning_rate}'\n",
    "        )\n",
    "\n",
    "        if technique == 'large_steps':\n",
    "            lambda_ = technique_param['lambda']\n",
    "            result_folder += f'_lambda_{format_float(lambda_)}'\n",
    "            override_bindings.append(\n",
    "                f'SceneConfig.large_steps_lambda={lambda_}'\n",
    "            )\n",
    "\n",
    "        # Ensure that the default tmp folder is used\n",
    "        override_bindings.append(\"SceneConfig.tmp_folder=''\")\n",
    "        override_bindings.append(\n",
    "            f'SceneConfig.use_conjugate_gradient_large_steps={use_conjugate_gradient_large_steps}'\n",
    "        )\n",
    "        override_bindings.append(\n",
    "            f'SceneConfig.use_gradient_filtering={use_gradient_filtering}'\n",
    "        )\n",
    "\n",
    "        if use_gradient_filtering:\n",
    "            result_folder += f'_sigma_d_{format_float(sigma_d)}'\n",
    "            result_folder += f'_F{filtering_steps}'\n",
    "            override_bindings.append(\n",
    "                f'SceneConfig.filtering_sigma_d={sigma_d}'\n",
    "            )\n",
    "            override_bindings.append(\n",
    "                f'SceneConfig.a_trous_filtering_steps={filtering_steps}'\n",
    "            )\n",
    "            override_bindings.append(\n",
    "                f'SceneConfig.log_domain_filtering={True}'\n",
    "            )\n",
    "\n",
    "        override_bindings.append(\n",
    "            f\"SceneConfig.result_folder='{result_folder}'\"\n",
    "        )\n",
    "\n",
    "        if technique == 'gradient_filtering':\n",
    "            gin_config_name = f'{scene_name}/naive'\n",
    "        else:\n",
    "            gin_config_name = f'{scene_name}/{technique}'\n",
    "\n",
    "        print(f'Next result location: {result_folder}')\n",
    "        if skip_existing and Path(result_folder).exists():\n",
    "            print('Skipping, already present')\n",
    "            continue\n",
    "\n",
    "        # Run the config\n",
    "        optimization_cli.run_config(gin_config_name, override_bindings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core import image_util\n",
    "from core import mitsuba_io\n",
    "\n",
    "from practical_reconstruction import figutils\n",
    "\n",
    "import drjit as dr\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib import gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGURE_DIR = \"figures/pdfs\"\n",
    "FIGURE_NAME = \"leather_bag\"\n",
    "\n",
    "def l2_error(ref,img):\n",
    "  return dr.mean(dr.square(ref-img)).array[0]\n",
    "\n",
    "def load_images_and_errors(scene_name, scene_name_ref):\n",
    "  start_iter = 31\n",
    "  end_iter = 127\n",
    "  images = []\n",
    "  \n",
    "  emitter_idx = 0\n",
    "  ref_view_name = \"ref_view_001\"\n",
    "\n",
    "  for iter in [start_iter, end_iter]:\n",
    "    suffix = f\"CameraClose_iter_{iter:03d}_{emitter_idx:03d}\"\n",
    "\n",
    "    images.append([\n",
    "      f\"results/{scene_name}/naive_lr_0_1/frames/{suffix}.exr\",\n",
    "      f\"results/{scene_name}/large_steps_lr_0_1_lambda_1_0/frames/{suffix}.exr\",\n",
    "      f\"results/{scene_name}/gradient_filtering_lr_0_1_sigma_d_0_001_F4/frames/{suffix}.exr\",\n",
    "      f\"results/{scene_name}/mipmap_pyramid_lr_0_01/frames/{suffix}.exr\",\n",
    "      f\"third_party/{scene_name_ref}/references/{ref_view_name}_emitter_{emitter_idx:03d}.exr\",\n",
    "    ])\n",
    "\n",
    "  image_exr_paths_iter_start, image_exr_paths_iter_end = images\n",
    "  num_images = len(image_exr_paths_iter_end)\n",
    "  assert num_images == len(image_exr_paths_iter_start)\n",
    "  images_exr_start, images_exr_end = [], []\n",
    "  images_start, images_end = [], []\n",
    "  for col in range(num_images):\n",
    "    exr_start = mitsuba_io.read_bitmap(image_exr_paths_iter_start[col])\n",
    "    exr_end = mitsuba_io.read_bitmap(image_exr_paths_iter_end[col])\n",
    "    tonemapped_start = image_util.tonemap(exr_start).convert(\n",
    "        pixel_format=mi.Bitmap.PixelFormat.RGB,\n",
    "        component_format=mi.Struct.Type.Float32,\n",
    "    )\n",
    "    tonemapped_end = image_util.tonemap(exr_end).convert(\n",
    "        pixel_format=mi.Bitmap.PixelFormat.RGB,\n",
    "        component_format=mi.Struct.Type.Float32,\n",
    "    )\n",
    "    images_exr_start.append(mi.TensorXf(exr_start))\n",
    "    images_exr_end.append(mi.TensorXf(exr_end))\n",
    "    images_start.append(np.array(tonemapped_start))\n",
    "    images_end.append(np.array(tonemapped_end))\n",
    "\n",
    "  error_fn = l2_error\n",
    "  errors_start, errors_end = [], []\n",
    "  ref_end = images_exr_end[-1]\n",
    "  ref_start = images_exr_start[-1]\n",
    "  for col in range(num_images - 1):\n",
    "    # End\n",
    "    img = images_exr_end[col]\n",
    "    error = error_fn(ref_end, img)\n",
    "    errors_end.append(error)\n",
    "    # Start\n",
    "    img = images_exr_start[col]\n",
    "    if ref_start.shape != img.shape:\n",
    "      error = error_fn(image_util.resize_to_width(ref_start, img.shape[1]), img)\n",
    "    else:\n",
    "      error = error_fn(ref_start, img)\n",
    "    errors_start.append(error)\n",
    "\n",
    "  flip_errors = [figutils.flip_error(img_end, images_end[-1]) for img_end in images_end]\n",
    "\n",
    "  return (\n",
    "      images_start,\n",
    "      images_end,\n",
    "      errors_start,\n",
    "      errors_end,\n",
    "      flip_errors,\n",
    "      start_iter,\n",
    "      end_iter,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure_grid_setup(image_shape,image_crop_shape,inner_space=0.0,outer_space=0.1):\n",
    "  # Image aspect ratios\n",
    "  h, w = image_shape\n",
    "  h_crop, w_crop = image_crop_shape\n",
    "  \n",
    "  # Spacing in the inner gridspec\n",
    "  bottom_inner_wspace = inner_space\n",
    "  # same vertical spacing as horizontal spacing\n",
    "  bottom_inner_hspace = bottom_inner_wspace * figutils.gridspec_aspect(\n",
    "      n_rows=1, n_cols=1, w=[w, w], h=[h, h_crop]\n",
    "  )\n",
    "  bottom_inner_rows = 2\n",
    "  bottom_inner_cols = 5\n",
    "  bottom_height_ratios = [h, h_crop]\n",
    "  bottom_inner_aspect = figutils.gridspec_aspect(\n",
    "      n_rows=bottom_inner_rows,\n",
    "      n_cols=bottom_inner_cols,\n",
    "      w=[w] * bottom_inner_cols,\n",
    "      h=bottom_height_ratios,\n",
    "      wspace=bottom_inner_wspace,\n",
    "      hspace=bottom_inner_hspace,\n",
    "  )\n",
    "\n",
    "  # Spacing in the main griddpec\n",
    "  outer_rows = 1\n",
    "  outer_cols = 1\n",
    "  outer_wspace = 0.0\n",
    "  outer_hspace = outer_space\n",
    "  \n",
    "  outer_aspect = figutils.gridspec_aspect(\n",
    "      n_rows=outer_rows,\n",
    "      n_cols=outer_cols,\n",
    "      w=1,\n",
    "      h=[1 / bottom_inner_aspect],\n",
    "      wspace=outer_wspace,\n",
    "      hspace=outer_hspace,\n",
    "  )\n",
    "  \n",
    "  fig = plt.figure(\n",
    "      1, figsize=(figutils.TEXT_WIDTH, figutils.TEXT_WIDTH / outer_aspect)\n",
    "  )\n",
    "\n",
    "  outer_gs = fig.add_gridspec(\n",
    "      outer_rows,\n",
    "      outer_cols,\n",
    "      hspace=outer_hspace,\n",
    "      wspace=outer_wspace,\n",
    "      height_ratios=[1 / bottom_inner_aspect],\n",
    "      width_ratios=[1],\n",
    "  )\n",
    "\n",
    "  bottom_inner_gs = gridspec.GridSpecFromSubplotSpec(\n",
    "      bottom_inner_rows,\n",
    "      bottom_inner_cols,\n",
    "      subplot_spec=outer_gs[0],\n",
    "      wspace=bottom_inner_wspace,\n",
    "      hspace=bottom_inner_hspace,\n",
    "      width_ratios=[h] * bottom_inner_cols,\n",
    "      height_ratios=bottom_height_ratios,\n",
    "  )\n",
    "  return (\n",
    "      fig,\n",
    "      ([bottom_inner_gs], bottom_inner_rows, bottom_inner_cols),\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images for the respective inner grids, compute crops and FLIP errors\n",
    "(\n",
    "    images_leather_bag_start,\n",
    "    images_leather_bag_end,\n",
    "    errors_leather_bag_start,\n",
    "    errors_leather_bag_end,\n",
    "    flip_errors_leather_bag,\n",
    "    start_iter_leather_bag,\n",
    "    end_iter_leather_bag,\n",
    ") = load_images_and_errors(\n",
    "    \"leather_bag\", \"leather_bag\"\n",
    ")\n",
    "\n",
    "leather_bag_crop_size = (500, 350)\n",
    "leather_bag_crop_offset = (290, 300)\n",
    "\n",
    "# Precompute crops\n",
    "images_leather_bag_crops = [\n",
    "    figutils.crop_image(img, leather_bag_crop_offset, leather_bag_crop_size)\n",
    "    for img in images_leather_bag_end\n",
    "]\n",
    "images_leather_bag_crops_flip = [\n",
    "    figutils.crop_image(img, leather_bag_crop_offset, leather_bag_crop_size)\n",
    "    for img in flip_errors_leather_bag\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.patheffects as pe\n",
    "\n",
    "matplotlib.rcParams.update(\n",
    "    {'axes.labelsize': 7}\n",
    ")\n",
    "\n",
    "# Generate the grid structure for the figure\n",
    "(\n",
    "    fig,\n",
    "    (bottom_inner_gs, bottom_inner_rows, bottom_inner_cols),\n",
    ") = figure_grid_setup(\n",
    "    image_shape=[1024, 1024],\n",
    "    image_crop_shape=[int(0.7*1024), 1024],\n",
    "    inner_space=0.02,\n",
    "    # outer_space=0.053,\n",
    "    outer_space=0.07,\n",
    ")\n",
    "\n",
    "\n",
    "def error_format(error, scale):\n",
    "  return f\"{error*scale:.3f}\"\n",
    "\n",
    "\n",
    "def add_iter_texts(ax, img_shape, linewidth=0.75):\n",
    "  ax.text(\n",
    "      20,\n",
    "      20,\n",
    "      f\"Iter. 32\",\n",
    "      color=\"white\",\n",
    "      ha=\"left\",\n",
    "      va=\"top\",\n",
    "      fontsize=8,\n",
    "      path_effects=[pe.withStroke(linewidth=linewidth, foreground=\"black\")],\n",
    "  )\n",
    "  ax.text(\n",
    "      img_shape[1] - 20,\n",
    "      img_shape[0] - 8,\n",
    "      \"Iter. 128\",\n",
    "      color=\"white\",\n",
    "      ha=\"right\",\n",
    "      va=\"bottom\",\n",
    "      fontsize=8,\n",
    "      path_effects=[pe.withStroke(linewidth=linewidth, foreground=\"black\")],\n",
    "  )\n",
    "\n",
    "\n",
    "line_width = 0.5\n",
    "\n",
    "crop_color = \"orange\"\n",
    "crop_1_color = \"orange\"\n",
    "crop_2_color = \"green\"\n",
    "\n",
    "titles = [\n",
    "    \"Standard Adam\",\n",
    "    figutils.LARGE_STEPS_NAME_SHORT,\n",
    "    figutils.GRAD_FILTERING_NAME,\n",
    "    \"Ours\",\n",
    "    \"Reference\",\n",
    "]\n",
    "\n",
    "scale = 1000\n",
    "scale_txt = figutils.math_label(r\"\\text{$\\times 10^3$}\",font_size=7)\n",
    "\n",
    "# Main figure generation\n",
    "# row 0 : image\n",
    "# row 1 : split(crop 1 / flip)\n",
    "ref_col = 4\n",
    "ours_col = 3\n",
    "filter_col = 2\n",
    "\n",
    "for scene_idx, inner_gs in enumerate(bottom_inner_gs):\n",
    "  for row in range(bottom_inner_rows):\n",
    "    for col in range(bottom_inner_cols):\n",
    "      \n",
    "      scene_images_start = images_leather_bag_start\n",
    "      scene_images_end = images_leather_bag_end\n",
    "      scene_crop_images = images_leather_bag_crops\n",
    "      errors_start = errors_leather_bag_start\n",
    "      errors_end = errors_leather_bag_end\n",
    "      flip_errors_crop = images_leather_bag_crops_flip\n",
    "      scene_name = \"Leather bag\"\n",
    "      crop_offset = leather_bag_crop_offset\n",
    "      crop_size = leather_bag_crop_size\n",
    "      boost =1.0\n",
    "\n",
    "      # Main image\n",
    "      if row == 0:\n",
    "        ax = fig.add_subplot(inner_gs[row, col])\n",
    "        figutils.disable_ticks(ax)\n",
    "        if col == 0:\n",
    "          ax.set_ylabel(r\"\\textsc{\" + scene_name + \"}\", labelpad=1.5,fontsize=8)\n",
    "\n",
    "        if col == ref_col:\n",
    "          ax.imshow(boost*scene_images_end[col])\n",
    "          # Rectangle Crops\n",
    "          rect_closeup = Rectangle(\n",
    "              crop_offset,\n",
    "              crop_size[0],\n",
    "              crop_size[1],\n",
    "              linewidth=line_width,\n",
    "              edgecolor=crop_color if row == 0 else \"green\",\n",
    "              facecolor=\"none\",\n",
    "          )\n",
    "          ax.add_patch(rect_closeup)\n",
    "        else:\n",
    "          img_combined, xline, yline = figutils.diagonal_split_image(\n",
    "              scene_images_start[col],\n",
    "              scene_images_end[col],\n",
    "              offset=0,\n",
    "              angle=20,\n",
    "          )\n",
    "          ax.plot(xline, yline, color=\"black\", linewidth=line_width)\n",
    "          ax.imshow(boost*img_combined, aspect=\"equal\")\n",
    "          add_iter_texts(ax, scene_images_end[col].shape)\n",
    "\n",
    "      else:\n",
    "        ax = fig.add_subplot(inner_gs[row, col])\n",
    "        figutils.disable_ticks(ax)\n",
    "\n",
    "        if col == 0:\n",
    "          ax.set_ylabel(\"Iter. 128 / FLIP\", labelpad=1.5,fontsize=8)\n",
    "\n",
    "        if col == ref_col:\n",
    "          ax.imshow(boost*scene_crop_images[col])\n",
    "          label = r\"$L_2$ \" + scale_txt + \" error (Iter. 32 / 128)\"\n",
    "        else:\n",
    "          img_combined, xline, yline = figutils.diagonal_split_image(\n",
    "              boost*scene_crop_images[col],\n",
    "              flip_errors_crop[col],\n",
    "              offset=0,\n",
    "              angle=20,\n",
    "          )\n",
    "          ax.plot(xline, yline, color=\"black\", linewidth=line_width)\n",
    "          ax.imshow(img_combined, aspect=\"equal\")\n",
    "          if col == ours_col:\n",
    "            label = (\n",
    "                error_format(errors_start[col], scale)\n",
    "                + \" / \"\n",
    "                + r\"\\textbf{\"\n",
    "                + error_format(errors_end[col], scale)\n",
    "                + r\"}\"\n",
    "            )\n",
    "          else:\n",
    "            label = (\n",
    "                error_format(errors_start[col], scale)\n",
    "                + \" / \"\n",
    "                + error_format(errors_end[col], scale)\n",
    "            )\n",
    "          # Add colored borders\n",
    "        ax.spines[:].set_color(crop_color)\n",
    "        ax.spines[:].set_linewidth(line_width)\n",
    "        ax.set_xlabel(label, labelpad=1.5)\n",
    "\n",
    "figutils.force_post_crop_size(fig, figutils.TEXT_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figutils.savefig(\n",
    "    fig,\n",
    "    name=Path(FIGURE_NAME),\n",
    "    fig_directory=Path(FIGURE_DIR),\n",
    "    dpi=300,\n",
    "    pad_inches=0.005,\n",
    "    bbox_inches=\"tight\",\n",
    "    compress=False,\n",
    "    target_width=figutils.TEXT_WIDTH,\n",
    "    backend=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inverse_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
