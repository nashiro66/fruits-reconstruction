{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayuf\\source\\repos\\practical-inverse-rendering-of-textured-and-translucent-appearance\n",
      "C:\\Users\\mayuf\\anaconda3\\envs\\practical-inverse-rendering\\python.exe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\mayuf\\\\source\\\\repos\\\\unbiased-inverse-volume-rendering\\\\mitsuba3\\\\build\\\\Release\\\\python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "def set_root_path():\n",
    "    if os.getcwd().endswith('figures'):\n",
    "        os.chdir('../')\n",
    "set_root_path()\n",
    "sys.path.append('python/')\n",
    "sys.path = [p for p in sys.path if \"unbiased-inverse-volume-rendering\" not in p]\n",
    "print(os.getcwd())\n",
    "print(sys.executable)\n",
    "os.environ.pop(\"PYTHONPATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayuf\\anaconda3\\envs\\practical-inverse-rendering\\lib\\site-packages\\mitsuba\\mitsuba_alias.cp310-win_amd64.pyd\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import mitsuba as mi\n",
    "mi.set_variant('cuda_ad_rgb')\n",
    "import inspect\n",
    "print(inspect.getfile(mi))\n",
    "from practical_reconstruction import optimization_cli\n",
    "from core import integrators\n",
    "from core import bsdfs\n",
    "from core import textures\n",
    "\n",
    "integrators.register()\n",
    "bsdfs.register()\n",
    "textures.register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** Running mipmap_pyramid with base learning rate 0.001 ********\n",
      "Next result location: results/kiwi_naive/mipmap_pyramid_lr_0_001\n",
      "Preparing Mitsuba scene for optimization\n",
      "Skipping already existing mitsuba scene: tmp\\kiwi_naive\\mts_scene\n",
      "Preparing references and sensors for optimization\n",
      "Rendering camera camera_000\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_000.exr\n",
      "Rendering camera camera_001\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_001.exr\n",
      "Rendering camera camera_002\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_002.exr\n",
      "Rendering camera camera_003\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_003.exr\n",
      "Rendering camera camera_004\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_004.exr\n",
      "Rendering camera camera_005\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_005.exr\n",
      "Rendering camera camera_006\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_006.exr\n",
      "Rendering camera camera_007\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_007.exr\n",
      "Rendering camera camera_008\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_008.exr\n",
      "Rendering camera camera_009\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_009.exr\n",
      "Rendering camera camera_010\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_010.exr\n",
      "Rendering camera camera_011\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_011.exr\n",
      "Rendering camera camera_012\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_012.exr\n",
      "Rendering camera camera_013\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_013.exr\n",
      "Rendering camera camera_014\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_014.exr\n",
      "Rendering camera camera_015\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_015.exr\n",
      "Rendering camera camera_016\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_016.exr\n",
      "Rendering camera camera_017\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_017.exr\n",
      "Rendering camera camera_018\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_018.exr\n",
      "Rendering camera camera_019\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_019.exr\n",
      "Rendering camera camera_020\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_020.exr\n",
      "Rendering camera camera_021\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_021.exr\n",
      "Rendering camera camera_022\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_022.exr\n",
      "Rendering camera camera_023\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_023.exr\n",
      "Rendering camera camera_024\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_024.exr\n",
      "Rendering camera camera_025\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_025.exr\n",
      "Rendering camera camera_026\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_026.exr\n",
      "Rendering camera camera_027\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_027.exr\n",
      "Rendering camera camera_028\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_028.exr\n",
      "Rendering camera camera_029\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_029.exr\n",
      "Rendering camera camera_030\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_030.exr\n",
      "Rendering camera camera_031\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_031.exr\n",
      "Rendering camera camera_032\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_032.exr\n",
      "Rendering camera camera_033\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_033.exr\n",
      "Rendering camera camera_034\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_034.exr\n",
      "Rendering camera camera_035\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_035.exr\n",
      "Rendering camera camera_036\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_036.exr\n",
      "Rendering camera camera_037\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_037.exr\n",
      "Rendering camera camera_038\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_038.exr\n",
      "Rendering camera camera_039\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_039.exr\n",
      "Rendering camera camera_040\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_040.exr\n",
      "Rendering camera camera_041\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_041.exr\n",
      "Rendering camera camera_042\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_042.exr\n",
      "Rendering camera camera_043\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_043.exr\n",
      "Rendering camera camera_044\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_044.exr\n",
      "Rendering camera camera_045\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_045.exr\n",
      "Rendering camera camera_046\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_046.exr\n",
      "Rendering camera camera_047\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_047.exr\n",
      "Rendering camera camera_048\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_048.exr\n",
      "Rendering camera camera_049\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_049.exr\n",
      "Rendering camera camera_050\n",
      "Reference found locally: tmp\\kiwi_naive\\references\\ref_view_050.exr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading references for sensor camera_000: 100%|██████████| 1/1 [00:00<00:00, 499.26it/s]\n",
      "Loading references for sensor camera_001: 100%|██████████| 1/1 [00:00<00:00, 666.50it/s]\n",
      "Loading references for sensor camera_002: 100%|██████████| 1/1 [00:00<00:00, 663.76it/s]\n",
      "Loading references for sensor camera_003: 100%|██████████| 1/1 [00:00<00:00, 666.71it/s]\n",
      "Loading references for sensor camera_004: 100%|██████████| 1/1 [00:00<00:00, 998.64it/s]\n",
      "Loading references for sensor camera_005: 100%|██████████| 1/1 [00:00<00:00, 2000.14it/s]\n",
      "Loading references for sensor camera_006: 100%|██████████| 1/1 [00:00<00:00, 665.45it/s]\n",
      "Loading references for sensor camera_007: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Loading references for sensor camera_008: 100%|██████████| 1/1 [00:00<00:00, 665.76it/s]\n",
      "Loading references for sensor camera_009: 100%|██████████| 1/1 [00:00<00:00, 665.02it/s]\n",
      "Loading references for sensor camera_010: 100%|██████████| 1/1 [00:00<00:00, 667.35it/s]\n",
      "Loading references for sensor camera_011: 100%|██████████| 1/1 [00:00<00:00, 499.32it/s]\n",
      "Loading references for sensor camera_012: 100%|██████████| 1/1 [00:00<00:00, 665.13it/s]\n",
      "Loading references for sensor camera_013: 100%|██████████| 1/1 [00:00<00:00, 666.93it/s]\n",
      "Loading references for sensor camera_014: 100%|██████████| 1/1 [00:00<00:00, 999.36it/s]\n",
      "Loading references for sensor camera_015: 100%|██████████| 1/1 [00:00<00:00, 665.55it/s]\n",
      "Loading references for sensor camera_016: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Loading references for sensor camera_017: 100%|██████████| 1/1 [00:00<00:00, 666.71it/s]\n",
      "Loading references for sensor camera_018: 100%|██████████| 1/1 [00:00<00:00, 665.76it/s]\n",
      "Loading references for sensor camera_019: 100%|██████████| 1/1 [00:00<00:00, 400.26it/s]\n",
      "Loading references for sensor camera_020: 100%|██████████| 1/1 [00:00<00:00, 497.78it/s]\n",
      "Loading references for sensor camera_021: 100%|██████████| 1/1 [00:00<00:00, 667.25it/s]\n",
      "Loading references for sensor camera_022: 100%|██████████| 1/1 [00:00<00:00, 667.35it/s]\n",
      "Loading references for sensor camera_023: 100%|██████████| 1/1 [00:00<00:00, 2000.14it/s]\n",
      "Loading references for sensor camera_024: 100%|██████████| 1/1 [00:00<00:00, 664.81it/s]\n",
      "Loading references for sensor camera_025: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Loading references for sensor camera_026: 100%|██████████| 1/1 [00:00<00:00, 1001.03it/s]\n",
      "Loading references for sensor camera_027: 100%|██████████| 1/1 [00:00<00:00, 332.12it/s]\n",
      "Loading references for sensor camera_028: 100%|██████████| 1/1 [00:00<00:00, 666.71it/s]\n",
      "Loading references for sensor camera_029: 100%|██████████| 1/1 [00:00<00:00, 999.12it/s]\n",
      "Loading references for sensor camera_030: 100%|██████████| 1/1 [00:00<00:00, 635.12it/s]\n",
      "Loading references for sensor camera_031: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Loading references for sensor camera_032: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Loading references for sensor camera_033: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Loading references for sensor camera_034: 100%|██████████| 1/1 [00:00<00:00, 601.51it/s]\n",
      "Loading references for sensor camera_035: 100%|██████████| 1/1 [00:00<00:00, 1996.34it/s]\n",
      "Loading references for sensor camera_036: 100%|██████████| 1/1 [00:00<00:00, 665.23it/s]\n",
      "Loading references for sensor camera_037: 100%|██████████| 1/1 [00:00<00:00, 166.62it/s]\n",
      "Loading references for sensor camera_038: 100%|██████████| 1/1 [00:00<00:00, 666.82it/s]\n",
      "Loading references for sensor camera_039: 100%|██████████| 1/1 [00:00<00:00, 667.14it/s]\n",
      "Loading references for sensor camera_040: 100%|██████████| 1/1 [00:00<00:00, 999.36it/s]\n",
      "Loading references for sensor camera_041: 100%|██████████| 1/1 [00:00<00:00, 498.97it/s]\n",
      "Loading references for sensor camera_042: 100%|██████████| 1/1 [00:00<00:00, 666.82it/s]\n",
      "Loading references for sensor camera_043: 100%|██████████| 1/1 [00:00<00:00, 999.36it/s]\n",
      "Loading references for sensor camera_044: 100%|██████████| 1/1 [00:00<00:00, 996.75it/s]\n",
      "Loading references for sensor camera_045: 100%|██████████| 1/1 [00:00<00:00, 667.14it/s]\n",
      "Loading references for sensor camera_046: 100%|██████████| 1/1 [00:00<00:00, 1000.79it/s]\n",
      "Loading references for sensor camera_047: 100%|██████████| 1/1 [00:00<00:00, 996.04it/s]\n",
      "Loading references for sensor camera_048: 100%|██████████| 1/1 [00:00<00:00, 648.47it/s]\n",
      "Loading references for sensor camera_049: 100%|██████████| 1/1 [00:00<00:00, 666.93it/s]\n",
      "Loading references for sensor camera_050: 100%|██████████| 1/1 [00:00<00:00, 1999.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing optimization variables\n",
      "Optimizing mat-kiwi's single_scattering_albedo from default value : [[0.5, 0.5, 0.5]]\n",
      "Optimizing mat-kiwi's extinction_coefficient from default value : [[10, 10, 10]]\n",
      "Optimizing mat-kiwi's hg_coefficient from default value : [[0, 0, 0]]\n",
      "Optimizing mat-kiwi's roughness from default value : [0.5]\n",
      "Learning rate for (texture) mat-kiwi (single_scattering_albedo) is  0.001\n",
      "Learning rate for (scalar) mat-kiwi (extinction_coefficient) is  1.0\n",
      "Learning rate for (texture) mat-kiwi (hg_coefficient) is  0.001\n",
      "Learning rate for (texture) mat-kiwi (roughness) is  0.001\n",
      "Starting optimization\n",
      "Resizing initial value for mat-kiwi.nested_bsdf.single_scattering_albedo.data/mat-kiwi.nested_bsdf.single_scattering_albedo.data to shape: (512, 512, 3)\n",
      "Skipping resizing as target shape is already reached.\n",
      "Resizing initial value for mat-kiwi.nested_bsdf.hg_coefficient.data/mat-kiwi.nested_bsdf.hg_coefficient.data to shape: (512, 512, 3)\n",
      "Skipping resizing as target shape is already reached.\n",
      "Resizing initial value for mat-kiwi.nested_bsdf.roughness.data/mat-kiwi.nested_bsdf.roughness.data to shape: (512, 512, 1)\n",
      "Skipping resizing as target shape is already reached.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rendering at resolution level 0 (width=436): 100%|██████████| 1024/1024 [16:26<00:00,  1.04it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-rendering final frame with 8192 spp\n",
      "Saving optimized textures\n",
      "--------- Done! ----------\n"
     ]
    }
   ],
   "source": [
    "def format_float(f):\n",
    "  \"\"\"Formats a float such that 0.1 becomes \"0_1\", 10.0 becomes \"10_0\", etc.\"\"\"\n",
    "  return str(f).replace('.', '_')\n",
    "\n",
    "scene_name = 'kiwi_naive'\n",
    "technique = 'mipmap_pyramid' # But all mipmaps have 1 level\n",
    "base_learning_rate = 0.001\n",
    "\n",
    "skip_existing = False\n",
    "\n",
    "print(\n",
    "    f'******** Running {technique} with base learning rate'\n",
    "    f' {base_learning_rate} ********'\n",
    ")\n",
    "\n",
    "override_bindings = []\n",
    "result_folder = f'results/{scene_name}/{technique}'\n",
    "\n",
    "result_folder += f'_lr_{format_float(base_learning_rate)}'\n",
    "override_bindings.append(\n",
    "    f'SceneConfig.base_learning_rate={base_learning_rate}'\n",
    ")\n",
    "\n",
    "# Ensure that the default tmp folder is used\n",
    "override_bindings.append(\"SceneConfig.tmp_folder=''\")\n",
    "override_bindings.append(\n",
    "    f'SceneConfig.use_gradient_filtering=False'\n",
    ")\n",
    "\n",
    "override_bindings.append(\n",
    "    f\"SceneConfig.result_folder='{result_folder}'\"\n",
    ")\n",
    "\n",
    "if technique == 'gradient_filtering':\n",
    "    gin_config_name = f'{scene_name}/naive'\n",
    "else:\n",
    "    gin_config_name = f'{scene_name}/{technique}'\n",
    "\n",
    "print(f'Next result location: {result_folder}')\n",
    "if skip_existing and Path(result_folder).exists():\n",
    "    print('Skipping, already present')\n",
    "else:\n",
    "    # Run the config\n",
    "    optimization_cli.run_config(gin_config_name, override_bindings, sss_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure starts here\n",
    "Make sure to run `figure_deng_optimization.ipynb` before as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from practical_reconstruction import figutils\n",
    "from matplotlib import gridspec\n",
    "\n",
    "def figure_grid_setup(image_shape,image_crop_shape,n_columns = 7,inner_space=0.0,outer_space=0.1,figwidth=figutils.TEXT_WIDTH):\n",
    "  # Image aspect ratios\n",
    "  h, w = image_shape\n",
    "  h_crop, w_crop = image_crop_shape\n",
    "\n",
    "  top_inner_rows = 1\n",
    "  top_inner_cols = n_columns\n",
    "  # Spacing in the inner gridspec\n",
    "  top_inner_wspace = inner_space\n",
    "  # same vertical spacing as horizontal spacing\n",
    "  top_inner_hspace = top_inner_wspace * figutils.gridspec_aspect(\n",
    "      n_rows=1, n_cols=1, w=[w]*top_inner_cols, h=[h]\n",
    "  )\n",
    "  top_height_ratios = [h]\n",
    "  top_inner_aspect = figutils.gridspec_aspect(\n",
    "      n_rows=top_inner_rows,\n",
    "      n_cols=top_inner_cols,\n",
    "      w=[w] * top_inner_cols,\n",
    "      h=top_height_ratios,\n",
    "      wspace=top_inner_wspace,\n",
    "      hspace=top_inner_hspace,\n",
    "  )\n",
    "  # print(top_inner_aspect)\n",
    "\n",
    "  # Spacing in the main griddpec\n",
    "  outer_rows = 4\n",
    "  outer_cols = 1\n",
    "  outer_wspace = 0.0\n",
    "  outer_hspace = outer_space\n",
    "  # If width is 1, we need the sum of the inverses for the height (single column)\n",
    "  # If height is 1, we need the sum for the width (single row)\n",
    "  outer_aspect = figutils.gridspec_aspect(\n",
    "      n_rows=outer_rows,\n",
    "      n_cols=outer_cols,\n",
    "      w=1,\n",
    "      h=[1 / top_inner_aspect] * outer_rows,\n",
    "      wspace=outer_wspace,\n",
    "      hspace=outer_hspace,\n",
    "  )\n",
    "\n",
    "  fig = plt.figure(\n",
    "      1, figsize=(figwidth, figwidth / outer_aspect)\n",
    "  )\n",
    "\n",
    "  outer_gs = fig.add_gridspec(\n",
    "      outer_rows,\n",
    "      outer_cols,\n",
    "      hspace=outer_hspace,\n",
    "      wspace=outer_wspace,\n",
    "      height_ratios=[1 / top_inner_aspect] * outer_rows,\n",
    "      width_ratios=[1]*outer_cols,\n",
    "  )\n",
    "\n",
    "  top_inner_gss = []\n",
    "  for row in range(outer_rows):\n",
    "    top_inner_gs = gridspec.GridSpecFromSubplotSpec(\n",
    "        top_inner_rows,\n",
    "        top_inner_cols,\n",
    "        subplot_spec=outer_gs[row],\n",
    "        wspace=top_inner_wspace,\n",
    "        hspace=top_inner_wspace,\n",
    "        width_ratios=[h] * top_inner_cols,\n",
    "        height_ratios=top_height_ratios,\n",
    "    )\n",
    "    top_inner_gss.append(top_inner_gs)\n",
    "\n",
    "  return (\n",
    "      fig,\n",
    "      (top_inner_gss, top_inner_rows, top_inner_cols),\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/kiwi/mipmap_pyramid_lr_0_0005/frames/camera_020_iter_4095_spp_8192.exr'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 57\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sensor_idx, crop_size, crop_offset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sensor_indices,crop_sizes,crop_offsets):\n\u001b[0;32m     56\u001b[0m   our_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults/kiwi/mipmap_pyramid_lr_0_0005/frames/camera_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msensor_idx\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_iter_4095_spp_8192.exr\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 57\u001b[0m   our_image \u001b[38;5;241m=\u001b[39m \u001b[43mmitsuba_io\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_bitmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mour_filename\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\n\u001b[0;32m     58\u001b[0m       pixel_format\u001b[38;5;241m=\u001b[39mmi\u001b[38;5;241m.\u001b[39mBitmap\u001b[38;5;241m.\u001b[39mPixelFormat\u001b[38;5;241m.\u001b[39mRGB,\n\u001b[0;32m     59\u001b[0m       component_format\u001b[38;5;241m=\u001b[39mmi\u001b[38;5;241m.\u001b[39mStruct\u001b[38;5;241m.\u001b[39mType\u001b[38;5;241m.\u001b[39mFloat32,\n\u001b[0;32m     60\u001b[0m   )\n\u001b[0;32m     61\u001b[0m   our_images\u001b[38;5;241m.\u001b[39mappend(image_util\u001b[38;5;241m.\u001b[39mtonemap(boost\u001b[38;5;241m*\u001b[39mour_image))\n\u001b[0;32m     62\u001b[0m   our_filename_naive \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscene_folder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/mipmap_pyramid_lr_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/frames/camera_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msensor_idx\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_iter_1023_spp_8192.exr\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\source\\repos\\practical-inverse-rendering-of-textured-and-translucent-appearance\\python\\core\\mitsuba_io.py:57\u001b[0m, in \u001b[0;36mread_bitmap\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Reads out a Mitsuba Bitmap image from the specified filepath.\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03mThis function is a thin wrapper around Mitsuba's Bitmap class to read image\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m  A Mitsuba Bitmap with the loaded image.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     56\u001b[0m stream \u001b[38;5;241m=\u001b[39m mi\u001b[38;5;241m.\u001b[39mMemoryStream()\n\u001b[1;32m---> 57\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     58\u001b[0m   stream\u001b[38;5;241m.\u001b[39mwrite(f\u001b[38;5;241m.\u001b[39mread())\n\u001b[0;32m     59\u001b[0m stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/kiwi/mipmap_pyramid_lr_0_0005/frames/camera_020_iter_4095_spp_8192.exr'"
     ]
    }
   ],
   "source": [
    "import drjit as dr\n",
    "import numpy as np\n",
    "from core import mitsuba_io\n",
    "from core import image_util\n",
    "\n",
    "def l2_error(ref, img):\n",
    "  return dr.mean(dr.square(ref - img)).array[0]\n",
    "\n",
    "\n",
    "def l1_error(ref, img):\n",
    "  return dr.mean(dr.abs(ref - img)).array[0]\n",
    "\n",
    "sensor_indices = [20, 1, 25, 12]\n",
    "\n",
    "lr = '0_001'\n",
    "normalmap_lr = '0_01'\n",
    "scene_folder = 'results/kiwi_naive'\n",
    "\n",
    "ref_scene_folder = (\n",
    "    'third_party/kiwi/unmasked_references'\n",
    ")\n",
    "ref_masked_scene_folder = (\n",
    "    'third_party/kiwi/references'\n",
    ")\n",
    "deng_scene_folder = (\n",
    "    'third_party/kiwi/deng_optimized/'\n",
    ")\n",
    "\n",
    "crop_sizes = [\n",
    "    (110, 110),\n",
    "    (126, 126),\n",
    "    (94, 94),\n",
    "    (113, 113),\n",
    "]\n",
    "\n",
    "crop_offsets = [\n",
    "    (159, 92),\n",
    "    (150, 75),\n",
    "    (168, 96),\n",
    "    (157, 86),\n",
    "]\n",
    "\n",
    "our_images = []\n",
    "our_images_naive = []\n",
    "ref_masked_images = []\n",
    "ref_images = []\n",
    "deng_images = []\n",
    "errors_l2_ours = []\n",
    "errors_l2_ours_naive = []\n",
    "errors_l2_deng = []\n",
    "\n",
    "boost = np.sqrt(2)\n",
    "\n",
    "for sensor_idx, crop_size, crop_offset in zip(sensor_indices,crop_sizes,crop_offsets):\n",
    "\n",
    "  our_filename = f'results/kiwi/mipmap_pyramid_lr_0_0005/frames/camera_{sensor_idx:03d}_iter_4095_spp_8192.exr'\n",
    "  our_image = mitsuba_io.read_bitmap(our_filename).convert(\n",
    "      pixel_format=mi.Bitmap.PixelFormat.RGB,\n",
    "      component_format=mi.Struct.Type.Float32,\n",
    "  )\n",
    "  our_images.append(image_util.tonemap(boost*our_image))\n",
    "  our_filename_naive = f'{scene_folder}/mipmap_pyramid_lr_{lr}/frames/camera_{sensor_idx:03d}_iter_1023_spp_8192.exr'\n",
    "  our_image_naive = mitsuba_io.read_bitmap(our_filename_naive).convert(\n",
    "      pixel_format=mi.Bitmap.PixelFormat.RGB,\n",
    "      component_format=mi.Struct.Type.Float32,\n",
    "  )\n",
    "  our_images_naive.append(image_util.tonemap(boost*our_image_naive))\n",
    "  ref_masked_filename = (\n",
    "      f'{ref_masked_scene_folder}/ref_view_{sensor_idx:03d}.exr'\n",
    "  )\n",
    "  ref_masked_image = mitsuba_io.read_bitmap(ref_masked_filename).convert(\n",
    "      pixel_format=mi.Bitmap.PixelFormat.RGB,\n",
    "      component_format=mi.Struct.Type.Float32,\n",
    "  )\n",
    "  ref_masked_images.append(image_util.tonemap(ref_masked_image))\n",
    "\n",
    "  ref_filename = f'{ref_scene_folder}/kiwi_{sensor_idx:05d}.exr'\n",
    "  ref_image = mitsuba_io.read_bitmap(ref_filename).convert(\n",
    "      pixel_format=mi.Bitmap.PixelFormat.RGB,\n",
    "      component_format=mi.Struct.Type.Float32,\n",
    "  )\n",
    "  ref_images.append(\n",
    "      image_util.tonemap(\n",
    "          boost*image_util.resize_to_width(ref_image, ref_image.size()[0] // 2)\n",
    "      )\n",
    "  )\n",
    "  deng_filename = f'{deng_scene_folder}/optimized_{sensor_idx:03d}_spp_256.exr'\n",
    "  deng_image = mitsuba_io.read_bitmap(deng_filename).convert(\n",
    "      pixel_format=mi.Bitmap.PixelFormat.RGB,\n",
    "      component_format=mi.Struct.Type.Float32,\n",
    "  )\n",
    "  deng_images.append(image_util.tonemap(boost*deng_image))\n",
    "\n",
    "  errors_l2_ours.append(\n",
    "      l2_error(\n",
    "          figutils.crop_image(\n",
    "              mi.TensorXf(ref_masked_image), crop_offset, crop_size\n",
    "          ),\n",
    "          figutils.crop_image(\n",
    "              mi.TensorXf(our_image), crop_offset, crop_size\n",
    "          ),\n",
    "      )\n",
    "  )\n",
    "\n",
    "  errors_l2_ours_naive.append(\n",
    "      l2_error(\n",
    "          figutils.crop_image(\n",
    "              mi.TensorXf(ref_masked_image), crop_offset, crop_size\n",
    "          ),\n",
    "          figutils.crop_image(\n",
    "              mi.TensorXf(our_image_naive), crop_offset, crop_size\n",
    "          ),\n",
    "      )\n",
    "  )\n",
    "  errors_l2_deng.append(\n",
    "      l2_error(\n",
    "          figutils.crop_image(\n",
    "              mi.TensorXf(ref_masked_image), crop_offset, crop_size\n",
    "          ),\n",
    "          figutils.crop_image(\n",
    "              mi.TensorXf(deng_image), crop_offset, crop_size\n",
    "          ),\n",
    "      )\n",
    "  )\n",
    "\n",
    "our_images = [\n",
    "    figutils.crop_image(np.array(image), crop_offsets[i], crop_sizes[i])\n",
    "    for i,image in enumerate(our_images)\n",
    "]\n",
    "our_images_naive = [\n",
    "    figutils.crop_image(np.array(image), crop_offsets[i], crop_sizes[i])\n",
    "    for i,image in enumerate(our_images_naive)\n",
    "]\n",
    "ref_images = [\n",
    "    figutils.crop_image(np.array(image), crop_offsets[i], crop_sizes[i])\n",
    "    for i,image in enumerate(ref_images)\n",
    "]\n",
    "deng_images = [\n",
    "    figutils.crop_image(np.array(image), crop_offsets[i], crop_sizes[i])\n",
    "    for i,image in enumerate(deng_images)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGURE_DIR = \"figures/pdfs\"\n",
    "FIGURE_NAME = \"deng_comparison_naive\"\n",
    "\n",
    "def error_format(error, scale):\n",
    "  return f\"{error*scale:.3f}\"\n",
    "\n",
    "(\n",
    "    fig,\n",
    "    (top_inner_gss, top_inner_rows, top_inner_cols),\n",
    ") = figure_grid_setup(\n",
    "    our_images[0].shape[:2],\n",
    "    our_images[0].shape[:2],\n",
    "    n_columns=len(sensor_indices),\n",
    "    inner_space=0.03,\n",
    "    outer_space=0.15,\n",
    "    figwidth=figutils.COLUMN_WIDTH,\n",
    ")\n",
    "\n",
    "\n",
    "scale = 1000\n",
    "scale_txt = figutils.math_label(r\"\\text{$\\times 10^3$}\")\n",
    "\n",
    "line_width = 0.75\n",
    "crop_color = 'orange'\n",
    "crop_color = (55/255.0,118/255.0,171/255.0,1.0)\n",
    "\n",
    "row_titles = [\n",
    "    \"Deng et al. 2022\",\n",
    "    \"Ours \\n(SSS + Roughness)\",\n",
    "    \"Ours \\n(Full model)\",\n",
    "    \"Reference\",\n",
    "]\n",
    "\n",
    "for row, top_inner_gs in enumerate(top_inner_gss):\n",
    "  if row == 0:\n",
    "    images = deng_images\n",
    "    errors = errors_l2_deng\n",
    "  elif row == 1:\n",
    "    images = our_images_naive \n",
    "    errors = errors_l2_ours_naive\n",
    "  elif row == 2:\n",
    "    images = our_images\n",
    "    errors = errors_l2_ours\n",
    "  elif row == 3:\n",
    "    images = ref_images\n",
    "\n",
    "  for col in range(top_inner_cols):\n",
    "    ax = fig.add_subplot(top_inner_gs[col])\n",
    "    ax.spines[:].set_color(crop_color)\n",
    "    ax.spines[:].set_linewidth(line_width)\n",
    "    figutils.disable_ticks(ax)\n",
    "    image = images[col]\n",
    "\n",
    "    # alpha_channel = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8) + 255\n",
    "    # black_pixels = np.all(image == 0, axis=-1)\n",
    "    # alpha_channel[black_pixels] = 0\n",
    "    # image_with_alpha = np.dstack((image, alpha_channel))\n",
    "\n",
    "    ax.imshow(image, aspect=\"equal\")\n",
    "    if col == 0:\n",
    "      ax.set_ylabel(row_titles[row],labelpad=1.5)\n",
    "\n",
    "    if row == 0 or row == 1 or row == 2:\n",
    "      label = error_format(errors[col], scale)\n",
    "    elif row == 3:\n",
    "      label = r\"$L_2$ \" + scale_txt + \" error\" if col == 0 else \"\"\n",
    "    ax.set_xlabel(label, labelpad=1.5)\n",
    "\n",
    "figutils.force_post_crop_size(fig, figutils.COLUMN_WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figutils.savefig(\n",
    "    fig,\n",
    "    name=Path(FIGURE_NAME),\n",
    "    fig_directory=Path(FIGURE_DIR),\n",
    "    dpi=300,\n",
    "    pad_inches=0.005,\n",
    "    bbox_inches=\"tight\",\n",
    "    compress=False,\n",
    "    target_width=figutils.COLUMN_WIDTH,\n",
    "    backend=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practical-inverse-rendering",
   "language": "python",
   "name": "practical-inverse-rendering"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
